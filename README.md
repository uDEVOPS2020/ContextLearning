# Deliverable-2.2

#Use case 1 
Antonio. 

#Use case 2 
The folder "Case 2" contains: 
- **Dataset**. This is the dataset used as illustrative example for this use case. It is derived by running a load on a well-known open-source benchmark for microservice  architecture (MSA), named Train Ticket [1].  The application simulates a train ticket booking system, composed of 41 microservices communicating to each other via REST over HTTP. Train ticket is  polyglot (e.g., Java, golang, Node.js, etc). 

- **Workload generation**. The dataset are generated by stressing the system with a workload. The folder contains the files to use and customise the tool Locust [2], which we exploited to generate the load. Locust is a distributed, open-source load testing tool that simulates concurrent users in an application for each benchmark. We customize the workload to reflect the behavior of real users. In total, we run XXXXXX queries per second for XXX time.  

- **Monitoring data**. The folder contains raw data gathered by monitoring. This includes: ..xxxxx,.   xxxxx,. xxxxx. For monitoring we used, .... .... .  

- *Benchmark.txt*. The file contains a link to the MSA under analysis.  

- **Code**. Python code files/scripts to: i) gather monitoring data, ii) parse the raw monitoring data and creating the dataset, iii) read the dataset and apply the algorithms for causal structure discovery to create a causal model, iv) rank the services in terms of most probable root cause for the observed performance behaviour, and v) present the result.  

To reproduce:  use the code files from steps iii) to v). 
Commands: 
./apply_causal_model.py dataset.txt
./rank_and_present.py
 
To replicate on a different subject, use Locust and monitoring scripts on the new subject, thus apply all the steps i) to v). 
Commands:
... 
...



Use case 3. 


